
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>26. Scrapy 框架-模拟登录-Request、Response - Hexo</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="Fechin,"> 
    <meta name="description" content="1. Scrapy-Request和Response（请求和响应） Scrapy的Request和Response对象用于爬网网站。
 通常，Request对象在爬虫程序中生成并传递到系统，直到它们,"> 
    <meta name="author" content="Jin Nian"> 
    <link rel="alternative" href="atom.xml" title="Hexo" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

    
<link rel="stylesheet" href="/css/diaspora.css">

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body class="loading">
    <span id="config-title" style="display:none">Hexo</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="https://github.com/Ana-behibak/Ana-behibak.github.io"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle">26. Scrapy 框架-模拟登录-Request、Response</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">26. Scrapy 框架-模拟登录-Request、Response</h1>
        <div class="stuff">
            <span>五月 06, 2020</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/python/" rel="tag">python</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>


        </div>
        <div class="content markdown">
            <h3 id="1-Scrapy-Request和Response（请求和响应）"><a href="#1-Scrapy-Request和Response（请求和响应）" class="headerlink" title="1. Scrapy-Request和Response（请求和响应）"></a>1. Scrapy-Request和Response（请求和响应）</h3><p> Scrapy的Request和Response对象用于爬网网站。</p>
<p> 通常，Request对象在爬虫程序中生成并传递到系统，直到它们到达下载程序，后者执行请求并返回一个Response对象，该对象返回到发出请求的爬虫程序。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">爬虫-&gt;&gt;Request: 创建</span><br><span class="line">Request-&gt;&gt;Response:获取下载数据</span><br><span class="line">Response-&gt;&gt;爬虫:数据</span><br></pre></td></tr></table></figure>

<h3 id="2-Request对象"><a href="#2-Request对象" class="headerlink" title="2. Request对象"></a>2. Request对象</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class scrapy.http.Request(url[, callback, method&#x3D;&#39;GET&#39;, headers, body, cookies, meta, encoding&#x3D;&#39;utf-8&#39;, priority&#x3D;0, dont_filter&#x3D;False, errback])</span><br></pre></td></tr></table></figure>

<p>一个Request对象表示一个HTTP请求，它通常是在爬虫生成，并由下载执行，从而生成Response</p>
<ul>
<li><p>参数</p>
<ul>
<li><p>url（string） - 此请求的网址</p>
</li>
<li><p>callback（callable） - 将使用此请求的响应（一旦下载）作为其第一个参数调用的函数。有关更多信息，请参阅下面的将附加数据传递给回调函数。如果请求没有指定回调，parse()将使用spider的 方法。请注意，如果在处理期间引发异常，则会调用errback。</p>
</li>
<li><p>method（string） - 此请求的HTTP方法。默认为’GET’。可设置为”GET”, “POST”, “PUT”等，且保证字符串大写</p>
</li>
<li><p>meta（dict） - 属性的初始值Request.meta,在不同的请求之间传递数据使用</p>
</li>
<li><p>body（str或unicode） - 请求体。如果unicode传递了a，那么它被编码为 str使用传递的编码（默认为utf-8）。如果 body没有给出，则存储一个空字符串。不管这个参数的类型，存储的最终值将是一个str（不会是unicode或None）。</p>
</li>
<li><p>headers（dict） - 这个请求的头。dict值可以是字符串（对于单值标头）或列表（对于多值标头）。如果 None作为值传递，则不会发送HTTP头.一般不需要</p>
</li>
<li><p>encoding: 使用默认的 ‘utf-8’ 就行。</p>
</li>
<li><p>cookie（dict或list） - 请求cookie。这些可以以两种形式发送。</p>
<ul>
<li>使用dict：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">request_with_cookies &#x3D; Request(url&#x3D;&quot;http:&#x2F;&#x2F;www.sxt.cn&#x2F;index&#x2F;login&#x2F;login.html&quot;,)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>使用列表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">request_with_cookies &#x3D; Request(url&#x3D;&quot;http:&#x2F;&#x2F;www.example.com&quot;,</span><br><span class="line">                             cookies&#x3D;[&#123;&#39;name&#39;: &#39;currency&#39;,</span><br><span class="line">                                      &#39;value&#39;: &#39;USD&#39;,</span><br><span class="line">                                      &#39;domain&#39;: &#39;example.com&#39;,</span><br><span class="line">                                      &#39;path&#39;: &#39;&#x2F;currency&#39;&#125;])</span><br></pre></td></tr></table></figure>
<p>后一种形式允许定制 cookie的属性domain和path属性。这只有在保存Cookie用于以后的请求时才有用</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">request_with_cookies &#x3D; Request(url&#x3D;&quot;http:&#x2F;&#x2F;www.example.com&quot;,</span><br><span class="line">                               cookies&#x3D;&#123;&#39;currency&#39;: &#39;USD&#39;, &#39;country&#39;: &#39;UY&#39;&#125;,</span><br><span class="line">                               meta&#x3D;&#123;&#39;dont_merge_cookies&#39;: True&#125;)</span><br></pre></td></tr></table></figure>

<h4 id="将附加数据传递给回调函数"><a href="#将附加数据传递给回调函数" class="headerlink" title="将附加数据传递给回调函数"></a>将附加数据传递给回调函数</h4><p>请求的回调是当下载该请求的响应时将被调用的函数。将使用下载的Response对象作为其第一个参数来调用回调函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def parse_page1(self, response):</span><br><span class="line">    item &#x3D; MyItem()</span><br><span class="line">    item[&#39;main_url&#39;] &#x3D; response.url</span><br><span class="line">    request &#x3D; scrapy.Request(&quot;http:&#x2F;&#x2F;www.example.com&#x2F;some_page.html&quot;,</span><br><span class="line">                             callback&#x3D;self.parse_page2)</span><br><span class="line">    request.meta[&#39;item&#39;] &#x3D; item</span><br><span class="line">    return request</span><br><span class="line"></span><br><span class="line">def parse_page2(self, response):</span><br><span class="line">    item &#x3D; response.meta[&#39;item&#39;]</span><br><span class="line">    item[&#39;other_url&#39;] &#x3D; response.url</span><br><span class="line">    return item</span><br></pre></td></tr></table></figure>
<h3 id="3-请求子类-FormRequest对象"><a href="#3-请求子类-FormRequest对象" class="headerlink" title="3 请求子类 FormRequest对象"></a>3 请求子类 FormRequest对象</h3><p>FormRequest类扩展了Request具有处理HTML表单的功能的基础。它使用lxml.html表单 从Response对象的表单数据预填充表单字段</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class scrapy.http.FormRequest(url[, formdata, ...])</span><br></pre></td></tr></table></figure>
<p>本FormRequest类增加了新的构造函数的参数。其余的参数与Request类相同，这里没有记录</p>
<ul>
<li>参数：formdata（元组的dict或iterable） - 是一个包含HTML Form数据的字典（或（key，value）元组的迭代），它将被url编码并分配给请求的主体。</li>
</ul>
<p>该FormRequest对象支持除标准以下类方法Request的方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classmethod from_response(response[, formname&#x3D;None, formid&#x3D;None, formnumber&#x3D;0, formdata&#x3D;None, formxpath&#x3D;None, formcss&#x3D;None, clickdata&#x3D;None, dont_click&#x3D;False, ...])</span><br></pre></td></tr></table></figure>

<p>返回一个新FormRequest对象，其中的表单字段值已预先<code>&lt;form&gt;</code>填充在给定响应中包含的HTML 元素中.</p>
<p>参数：</p>
<ul>
<li>response（Responseobject） - 包含将用于预填充表单字段的HTML表单的响应</li>
<li>formname（string） - 如果给定，将使用name属性设置为此值的形式</li>
<li>formid（string） - 如果给定，将使用id属性设置为此值的形式</li>
<li>formxpath（string） - 如果给定，将使用匹配xpath的第一个表单</li>
<li>formcss（string） - 如果给定，将使用匹配css选择器的第一个形式</li>
<li>formnumber（integer） - 当响应包含多个表单时要使用的表单的数量。第一个（也是默认）是0</li>
<li>formdata（dict） - 要在表单数据中覆盖的字段。如果响应元素中已存在字段，则其值将被在此参数中传递的值覆盖</li>
<li>clickdata（dict） - 查找控件被点击的属性。如果没有提供，表单数据将被提交，模拟第一个可点击元素的点击。除了html属性，控件可以通过其相对于表单中其他提交表输入的基于零的索引，通过nr属性来标识</li>
<li>dont_click（boolean） - 如果为True，表单数据将在不点击任何元素的情况下提交</li>
</ul>
<h4 id="3-1-请求使用示例"><a href="#3-1-请求使用示例" class="headerlink" title="3.1 请求使用示例"></a>3.1 请求使用示例</h4><p>使用FormRequest通过HTTP POST发送数据</p>
<p>如果你想在你的爬虫中模拟HTML表单POST并发送几个键值字段，你可以返回一个FormRequest对象（从你的爬虫）像这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">return [FormRequest(url&#x3D;&quot;http:&#x2F;&#x2F;www.example.com&#x2F;post&#x2F;action&quot;,</span><br><span class="line">                    formdata&#x3D;&#123;&#39;name&#39;: &#39;John Doe&#39;, &#39;age&#39;: &#39;27&#39;&#125;,</span><br><span class="line">                    callback&#x3D;self.after_post)]</span><br></pre></td></tr></table></figure>
<p>使用FormRequest.from_response（）来模拟用户登录</p>
<p>网站通常通过元素（例如会话相关数据或认证令牌（用于登录页面））提供预填充的表单字段。进行剪贴时，您需要自动预填充这些字段，并且只覆盖其中的一些，例如用户名和密码。您可以使用 此作业的方法。这里有一个使用它的爬虫示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;input type&#x3D;&quot;hidden&quot;&gt; FormRequest.from_response()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class LoginSpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;example.com&#39;</span><br><span class="line">    start_urls &#x3D; [&#39;http:&#x2F;&#x2F;www.example.com&#x2F;users&#x2F;login.php&#39;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        return scrapy.FormRequest.from_response(</span><br><span class="line">            response,</span><br><span class="line">            formdata&#x3D;&#123;&#39;username&#39;: &#39;john&#39;, &#39;password&#39;: &#39;secret&#39;&#125;,</span><br><span class="line">            callback&#x3D;self.after_login</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def after_login(self, response):</span><br><span class="line">        # check login succeed before going on</span><br><span class="line">        if &quot;authentication failed&quot; in response.body:</span><br><span class="line">            self.logger.error(&quot;Login failed&quot;)</span><br><span class="line">            return</span><br><span class="line"></span><br><span class="line">        # continue scraping with authenticated session...</span><br></pre></td></tr></table></figure>
<h3 id="4-响应对象"><a href="#4-响应对象" class="headerlink" title="4 响应对象"></a>4 响应对象</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class scrapy.http.Response(url[, status&#x3D;200, headers&#x3D;None, body&#x3D;b&#39;&#39;, flags&#x3D;None, request&#x3D;None])</span><br></pre></td></tr></table></figure>
<p>一个Response对象表示的HTTP响应，这通常是下载（由下载），并供给到爬虫进行处理</p>
<p>参数：</p>
<ul>
<li>url（string） - 此响应的URL</li>
<li>status（integer） - 响应的HTTP状态。默认为200</li>
<li>headers（dict） - 这个响应的头。dict值可以是字符串（对于单值标头）或列表（对于多值标头）</li>
<li>body（str） - 响应体。它必须是str，而不是unicode，除非你使用一个编码感知响应子类，如 TextResponse</li>
<li>flags（list） - 是一个包含属性初始值的 Response.flags列表。如果给定，列表将被浅复制</li>
<li>request（Requestobject） - 属性的初始值Response.request。这代表Request生成此响应</li>
</ul>
<h3 id="5-模拟登录"><a href="#5-模拟登录" class="headerlink" title="5 模拟登录"></a>5 模拟登录</h3><p><strong>用的函数：</strong></p>
<ul>
<li><p>start_requests()可以返回一个请求给爬虫的起始网站，这个返回的请求相当于start_urls，start_requests()返回的请求会替代start_urls里的请求</p>
</li>
<li><p>Request()get请求，可以设置，url、cookie、回调函数</p>
</li>
<li><p>FormRequest.from_response()表单post提交，第一个必须参数，上一次响应cookie的response对象，其他参数，cookie、url、表单内容等</p>
</li>
<li><p>yield Request()可以将一个新的请求返回给爬虫执行</p>
</li>
</ul>
<p><strong>在发送请求时cookie的操作，</strong></p>
<ul>
<li>meta={‘cookiejar’:1}表示开启cookie记录，首次请求时写在Request()里</li>
<li>meta={‘cookiejar’:response.meta[‘cookiejar’]}表示使用上一次response的cookie，写在FormRequest.from_response()里post授权</li>
<li>meta={‘cookiejar’:True}表示使用授权后的cookie访问需要登录查看的页面</li>
</ul>
<p><strong>获取Scrapy框架Cookies</strong></p>
<p><strong>样例代码</strong></p>
<p><code>start_requests()</code>方法，可以返回一个请求给爬虫的起始网站，这个返回的请求相当于start_urls，start_requests()返回的请求会替代start_urls里的请求</p>
<p>在发送请求时cookie的操作</p>
<p><code>meta={&#39;cookiejar&#39;:1}</code>表示开启cookie记录，首次请求时写在Request()里</p>
<p><code>meta={&#39;cookiejar&#39;:response.meta[&#39;cookiejar&#39;]}</code>表示使用上一次response的cookie，写在Request里post授权</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">from scrapy import Request</span><br><span class="line">from scrapy import FormRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SxtSpiderSpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;sxt1&#39;</span><br><span class="line">    allowed_domains &#x3D; [&#39;sxt.cn&#39;]</span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        return [Request(&#39;http:&#x2F;&#x2F;www.sxt.cn&#x2F;index&#x2F;login&#x2F;login.html&#39;, meta&#x3D;&#123;&#39;cookiejar&#39;: 1&#125;, callback&#x3D;self.parse)]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        formdata &#x3D; &#123;</span><br><span class="line">            &quot;user&quot;: &quot;17703181473&quot;, &quot;password&quot;: &quot;123456&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        return FormRequest(                                        formdata&#x3D;formdata,</span><br><span class="line">                                        url&#x3D;&#39;http:&#x2F;&#x2F;www.sxt.cn&#x2F;index&#x2F;login&#x2F;login.html&#39;,</span><br><span class="line">                                        meta&#x3D;&#123;&#39;cookiejar&#39;: response.meta[&#39;cookiejar&#39;]&#125;,</span><br><span class="line">                                        callback&#x3D;self.login_after)</span><br><span class="line"></span><br><span class="line">    def login_after(self, response):</span><br><span class="line">        yield scrapy.Request(&#39;http:&#x2F;&#x2F;www.sxt.cn&#x2F;index&#x2F;user.html&#39;,</span><br><span class="line">                             meta&#x3D;&#123;&quot;cookiejar&quot;: response.meta[&#39;cookiejar&#39;]&#125;,</span><br><span class="line">                             callback&#x3D;self.next)</span><br><span class="line">    def next(self,response):</span><br><span class="line">        print(response.text)</span><br></pre></td></tr></table></figure>
            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title='0' data-url='http://link.hhtjim.com/163/425570952.mp3'></li>
                        
                    
                        
                            <li title='1' data-url='http://link.hhtjim.com/163/425570952.mp3'></li>
                        
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
		data-enable='true'
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d='false'
    >查看评论</div>


    </div>
    
        <div class='side'>
			<ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Scrapy-Request和Response（请求和响应）"><span class="toc-number">1.</span> <span class="toc-text">1. Scrapy-Request和Response（请求和响应）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Request对象"><span class="toc-number">2.</span> <span class="toc-text">2. Request对象</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#将附加数据传递给回调函数"><span class="toc-number">2.1.</span> <span class="toc-text">将附加数据传递给回调函数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-请求子类-FormRequest对象"><span class="toc-number">3.</span> <span class="toc-text">3 请求子类 FormRequest对象</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-请求使用示例"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 请求使用示例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-响应对象"><span class="toc-number">4.</span> <span class="toc-text">4 响应对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-模拟登录"><span class="toc-number">5.</span> <span class="toc-text">5 模拟登录</span></a></li></ol>	
        </div>
    
</div>


    </div>
</div>
</body>

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>






</html>
